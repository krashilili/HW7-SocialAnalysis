{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key,\n",
    "                    consumer_secret,\n",
    "                    access_token,\n",
    "                    access_token_secret)\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target accounts\n",
    "news_orgs = ['@BBC','@CBS','@CNN','@FoxNews','@nytimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for the sentiment analysis of each news org\n",
    "def get_sentiments(target_user):\n",
    "    # Variables for holding sentiments\n",
    "    sentiments = []\n",
    "\n",
    "    # Counter\n",
    "    counter = 1\n",
    "\n",
    "    # Variable for max_id\n",
    "    oldest_tweet = None\n",
    "    \n",
    "    # Loop through 6 pages of tweets (total 120 tweets)\n",
    "    for x in range(6):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(target_user, max_id = oldest_tweet)\n",
    "\n",
    "        # Loop through all tweets \n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Print Tweets\n",
    "            # print(\"Tweet %s: %s\" % (counter, tweet[\"text\"]))\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "#             pos = results[\"pos\"]\n",
    "#             neu = results[\"neu\"]\n",
    "#             neg = results[\"neg\"]\n",
    "            tweets_ago = counter\n",
    "\n",
    "            # Get Tweet ID, subtract 1, and assign to oldest_tweet\n",
    "            oldest_tweet = tweet['id'] - 1\n",
    "\n",
    "            # Add sentiments for each tweet into a list\n",
    "            sentiments.append({\n",
    "#                 \"Date\": tweet[\"created_at\"], \n",
    "                                \"News Org\":target_user,\n",
    "                               \"Compound\": compound,\n",
    "#                                \"Positive\": pos,\n",
    "#                                \"Negative\": neu,\n",
    "#                                \"Neutral\": neg,\n",
    "                               \"Tweets Ago\": counter})\n",
    "\n",
    "            # Add to counter \n",
    "            counter += 1\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = list()\n",
    "for target in news_orgs:\n",
    "    sentiments += get_sentiments(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>News Org</th>\n",
       "      <th>Tweets Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>@BBC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6249</td>\n",
       "      <td>@BBC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>@BBC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2960</td>\n",
       "      <td>@BBC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3612</td>\n",
       "      <td>@BBC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound News Org  Tweets Ago\n",
       "0    0.0000     @BBC           1\n",
       "1    0.6249     @BBC           2\n",
       "2    0.0000     @BBC           3\n",
       "3    0.2960     @BBC           4\n",
       "4   -0.3612     @BBC           5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sentiments to DataFrame# Conve \n",
    "sentiments_pd = pd.DataFrame.from_dict(sentiments)\n",
    "sentiments_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments\n",
    "sns.set_style(\"darkgrid\")\n",
    "colors = {'BBC':'lightcoral',\n",
    "          'Suburban':'lightskyblue',\n",
    "          'Rural':'gold'}\n",
    "\n",
    "g = sns.lmplot(x='Tweets Ago',\n",
    "               y='Compound',\n",
    "               data=sentiments_pd,\n",
    "               scatter_kws={'edgecolors':'black',\n",
    "                            'linewidths':1.2,\n",
    "                            'alpha': 0.7},             \n",
    "               hue='City Types',\n",
    "               palette=colors,\n",
    "               fit_reg=False,\n",
    "               size=10,\n",
    "               aspect=1,\n",
    "               legend_out=False)\n",
    "\n",
    "# set xlim and ylim\n",
    "g.ax.set_xlim(0,38)\n",
    "g.ax.set_ylim(18,51)\n",
    "# title, labels\n",
    "g.ax.set_title(\"Pyber Ride Sharing Data (2018)\", fontsize=15)\n",
    "g.ax.set_xlabel(\"Total Number of Rides (Per City)\", fontsize=15)\n",
    "g.ax.set_ylabel(\"Average Fare ($)\",fontsize=15)\n",
    "g.ax.text(40,37, \"Note:\\nCircle size correlates with driver count per city.\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
